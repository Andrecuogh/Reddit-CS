{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10365929"
      },
      "source": [
        "# DID REDDITORS INFLUENCE CREDIT SUISSE COLLAPSE?\n",
        "This research aims to determine if the Reddit financial community had had any power in the decline of Credit Suisse's stocks price. It has been conducted as a sentiment analysis of Reddit's posts, using Python, NLP and machine learning techniques"
      ],
      "id": "10365929"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment set up"
      ],
      "metadata": {
        "id": "llXdGmEpt2o4"
      },
      "id": "llXdGmEpt2o4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "236509a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20acc47b-a387-4fed-86ae-7d8a3b65280a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: arch in /usr/local/lib/python3.10/dist-packages (6.2.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from arch) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from arch) (1.11.3)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from arch) (1.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.12 in /usr/local/lib/python3.10/dist-packages (from arch) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->arch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->arch) (2023.3.post1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->arch) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->arch) (23.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels>=0.12->arch) (1.16.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "## Import packages\n",
        "\n",
        "!pip install emoji arch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import re\n",
        "import os\n",
        "import emoji\n",
        "import nltk\n",
        "import arch\n",
        "\n",
        "from PIL import Image\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder, QuadgramCollocationFinder\n",
        "from nltk.collocations import BigramAssocMeasures, TrigramAssocMeasures, QuadgramAssocMeasures\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from gensim.models import Word2Vec\n",
        "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
        "from matplotlib.patches import Ellipse\n",
        "from matplotlib.patches import Rectangle\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "nltk.download(['punkt', 'stopwords', 'vader_lexicon', 'averaged_perceptron_tagger', 'wordnet'], quiet=True)"
      ],
      "id": "236509a3"
    },
    {
      "cell_type": "code",
      "source": [
        "## Matplotlibe style for figures\n",
        "\n",
        "plt.rcdefaults()\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['axes.spines.top'] = False  # Hide top spine\n",
        "plt.rcParams['axes.spines.right'] = False  # Hide right spine\n",
        "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=['#003662'])\n",
        "plt.rcParams['xtick.labelsize'] = 10\n",
        "plt.rcParams['ytick.labelsize'] = 10\n",
        "plt.rcParams['ytick.direction'] = 'in'  # Tick marks inside the plot\n",
        "plt.rcParams['lines.color'] = 'k'\n",
        "plt.rcParams['grid.color'] = '0.8'  # Light gray grid lines\n",
        "plt.rcParams['grid.linestyle'] = '--'  # Dashed grid lines\n",
        "plt.rcParams['grid.linewidth'] = 0.5  # Adjust grid line width\n",
        "plt.rcParams['grid.alpha'] = 0.7  # Set grid line transparency"
      ],
      "metadata": {
        "id": "8bcWxhojL9VZ"
      },
      "id": "8bcWxhojL9VZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def StandScal(df):\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype != 'O':\n",
        "            mean = df[col].dropna().mean()\n",
        "            std = df[col].dropna().std()\n",
        "            for i in df.index:\n",
        "                if not np.isnan(df.loc[i, col]):\n",
        "                    df.loc[i, col] = (df.loc[i, col]-mean)/std\n",
        "                else:\n",
        "                    continue\n",
        "    return df"
      ],
      "metadata": {
        "id": "m5ANPR_q9BcX"
      },
      "id": "m5ANPR_q9BcX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Processing"
      ],
      "metadata": {
        "id": "21K62qJ-xeFd"
      },
      "id": "21K62qJ-xeFd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removal of unrelevant posts"
      ],
      "metadata": {
        "id": "egEUxUi46Mj2"
      },
      "id": "egEUxUi46Mj2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "68e86840",
        "outputId": "953a75b8-22e2-4d6a-ebe8-0700b0effdcf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                               title post_id  \\\n",
              "0  I thought of you guys when I listened to this ...  ek5jql   \n",
              "1                   Historical analyst target prices  gtz5kk   \n",
              "2  The Swiss government just borrowed $9 billion ...  y83ebs   \n",
              "3  REALITY CHECK: Peter Hahn, one of the major fi...  xuht8x   \n",
              "4   *** Ultimate AMC Timeline (Updated April 25) ***  mygdc3   \n",
              "\n",
              "                  date  karma  upvote  \\\n",
              "0  2020-01-05 00:58:56      0    0.50   \n",
              "1  2020-05-31 13:36:45      0    0.33   \n",
              "2  2022-10-19 13:55:33   3431    0.95   \n",
              "3  2022-10-03 12:15:15   1957    0.89   \n",
              "4  2021-04-25 20:05:47   2756    0.99   \n",
              "\n",
              "                                             content    subreddit  \n",
              "0  Bloomberg View columnist Barry Ritholtz interv...  algotrading  \n",
              "1  Analysts' stock reports from investment banks ...  algotrading  \n",
              "2                                                NaN     amcstock  \n",
              "3  I think it's important for us to manage expect...     amcstock  \n",
              "4  # [CLICK HERE to go to the April 28 update.](h...     amcstock  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e070402-6a98-4223-b547-9c1772dc5370\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>post_id</th>\n",
              "      <th>date</th>\n",
              "      <th>karma</th>\n",
              "      <th>upvote</th>\n",
              "      <th>content</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I thought of you guys when I listened to this ...</td>\n",
              "      <td>ek5jql</td>\n",
              "      <td>2020-01-05 00:58:56</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>Bloomberg View columnist Barry Ritholtz interv...</td>\n",
              "      <td>algotrading</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Historical analyst target prices</td>\n",
              "      <td>gtz5kk</td>\n",
              "      <td>2020-05-31 13:36:45</td>\n",
              "      <td>0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>Analysts' stock reports from investment banks ...</td>\n",
              "      <td>algotrading</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Swiss government just borrowed $9 billion ...</td>\n",
              "      <td>y83ebs</td>\n",
              "      <td>2022-10-19 13:55:33</td>\n",
              "      <td>3431</td>\n",
              "      <td>0.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>amcstock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>REALITY CHECK: Peter Hahn, one of the major fi...</td>\n",
              "      <td>xuht8x</td>\n",
              "      <td>2022-10-03 12:15:15</td>\n",
              "      <td>1957</td>\n",
              "      <td>0.89</td>\n",
              "      <td>I think it's important for us to manage expect...</td>\n",
              "      <td>amcstock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*** Ultimate AMC Timeline (Updated April 25) ***</td>\n",
              "      <td>mygdc3</td>\n",
              "      <td>2021-04-25 20:05:47</td>\n",
              "      <td>2756</td>\n",
              "      <td>0.99</td>\n",
              "      <td># [CLICK HERE to go to the April 28 update.](h...</td>\n",
              "      <td>amcstock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e070402-6a98-4223-b547-9c1772dc5370')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e070402-6a98-4223-b547-9c1772dc5370 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e070402-6a98-4223-b547-9c1772dc5370');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1b9ebf7-0f72-400d-a1f5-0b7291793903\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1b9ebf7-0f72-400d-a1f5-0b7291793903')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1b9ebf7-0f72-400d-a1f5-0b7291793903 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Removing unrelevant post\n",
        "\n",
        "# Import the dataset\n",
        "df = pd.read_csv('Rawdata.csv', index_col = 0)\n",
        "display(df.head())\n",
        "\n",
        "# Join title and text\n",
        "df.fillna('', inplace=True)\n",
        "df['text'] = df['title'] + ' ' + df['content']\n",
        "df.drop(['title', 'content'], axis=1, inplace=True)\n",
        "df['karma'] += 1\n",
        "\n",
        "# Number of words in posts\n",
        "df['length'] = 0\n",
        "for i in df.index:\n",
        "    df.loc[i, 'length'] = len(df.loc[i, 'text'].split())\n",
        "\n",
        "# Filter for period: 01/08/2022 - 20/03/2023\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df[df['date'] > pd.to_datetime('2022-08-01')].copy()\n",
        "df = df[df['date'] < pd.to_datetime('2023-03-20')].copy()\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Remove stock news post\n",
        "forbidden_words = ['CLICK HERE', 'Downgrades:', 'volume leaders', 'Q4 2022 Letters & Reports', 'Holdings Inc']\n",
        "to_save = ['11ushdl', 'zt4t1y', 'yckj9o', 'ybqjek']\n",
        "to_drop = []\n",
        "for i in df.index:\n",
        "    for forbidden in forbidden_words:\n",
        "        if forbidden in df.loc[i, 'text']:\n",
        "            if df.loc[i, 'post_id'] not in to_save:\n",
        "                to_drop.append(i)\n",
        "\n",
        "df.drop(to_drop, inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "id": "68e86840"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Extraction"
      ],
      "metadata": {
        "id": "RWK7gonb6Vj6"
      },
      "id": "RWK7gonb6Vj6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd03cc51"
      },
      "outputs": [],
      "source": [
        "## Sentiment extraction\n",
        "\n",
        "# Emoticon extraction\n",
        "df['emojis'] = ''\n",
        "for i in df.index:\n",
        "    df.loc[i, 'emojis'] = ' '.join([emoji.demojize(c) for c in df.loc[i, 'text'] if c in emoji.EMOJI_DATA])\n",
        "emoj = pd.read_excel('Emojissent.xlsx')\n",
        "emoj['Description'] = [emoji.demojize(c) for c in emoj['Symbol']]\n",
        "emoj.drop('Symbol', axis=1, inplace=True)\n",
        "emoj.set_index('Description', inplace=True)\n",
        "new_words=emoj['Sentiment'].to_dict()\n",
        "\n",
        "# Text cleaning\n",
        "for i in df.index:\n",
        "    text = df.loc[i, 'text']\n",
        "    whole = []\n",
        "    for element in sent_tokenize(text):\n",
        "        clean = element.lower()\n",
        "        clean = re.sub(r'\\bcs\\b', 'credit suisse', clean)\n",
        "        clean = re.sub(r'\\bdd\\b', 'double down', clean)\n",
        "        clean = re.sub(r'\\bcds\\b', 'default swap', clean)\n",
        "        clean = re.sub(r'u\\.s\\.', 'usa', clean)\n",
        "        clean = re.sub(r'&#[A-Za-z0-9]+', '', clean)\n",
        "        clean = re.sub(r'tl(;|)dr', '', clean)\n",
        "        clean = re.sub(r'\\([^()]*\\)', '', clean)\n",
        "        clean = re.sub(r'\\[[^\\[\\]]*\\]', '', clean)\n",
        "        clean = re.sub(r\"(?:\\@|http?|https?|www)\\S+\", \"\", clean)\n",
        "        clean = re.sub(r\"don\\'t\", 'do not', clean)\n",
        "        clean = re.sub(r\"doesn\\'t\", 'does not', clean)\n",
        "        clean = re.sub(r'\\’', \"'\", clean)\n",
        "        clean = re.sub(r\"[^A-Za-z\\'\\?\\!]\", ' ', clean)\n",
        "        clean = re.sub(r'\\b\\w\\b', '', clean)\n",
        "        clean = re.sub(r'\\bcredit\\b', '', clean)\n",
        "        wo_spaces = clean.split()\n",
        "        clean = ' '.join(wo_spaces)\n",
        "        whole.append(clean)\n",
        "    clean = ' '.join(whole)\n",
        "    df.loc[i, 'text'] = clean\n",
        "\n",
        "# Computing sentiment scores\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.lexicon.update(new_words)\n",
        "sentiment_scores = [sia.polarity_scores(doc)['compound'] for doc in df['text'] + ' ' + df['emojis']]\n",
        "df['sentiment'] = sentiment_scores\n",
        "df.to_csv('Processeddata.csv')"
      ],
      "id": "dd03cc51"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploratory analysis: figures"
      ],
      "metadata": {
        "id": "i94uMjS36ZEA"
      },
      "id": "i94uMjS36ZEA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "563ee1dd"
      },
      "outputs": [],
      "source": [
        "## Exploratory analysis: length, subreddit, sentiment distribution\n",
        "\n",
        "# Lenght of the post\n",
        "perc = np.arange(10, 100, 10)\n",
        "quant = np.percentile(df['length'], perc)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(np.arange(1,10), quant)\n",
        "ax.set_title(\"Percentile distribution of the posts' length\")\n",
        "ax.set_xticks(np.arange(1,10), labels=[str(i)+'%' for i in perc])\n",
        "ax.set_axisbelow(True)\n",
        "ax.set_xlabel('Percentile')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.grid()\n",
        "for p in range(len(perc)):\n",
        "  ax.text(np.arange(1,10)[p], quant[p]+4, int(quant[p]),\n",
        "             fontsize=9, horizontalalignment='center')\n",
        "mean_max_box = f'Mean: {int(df[\"length\"].mean())}\\n\\nMax: {int(df[\"length\"].max())}'\n",
        "ax.text(1.7, 230, mean_max_box, fontsize=12, color='black', bbox=dict(facecolor=(0.95, 0.95, 0.95), edgecolor='black'))\n",
        "fig.savefig(\"Post length\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Top 10 Subreddit\n",
        "subr = df[['subreddit', 'karma']].groupby('subreddit').count().sort_values('karma', ascending=False).head(10).sort_index()\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(np.arange(len(subr)), subr['karma'])\n",
        "ax.set_title('Posts downloaded for the 10 major subreddits')\n",
        "ax.set_xticks(np.arange(len(subr)), subr.index, rotation=45)\n",
        "ax.set_ylabel('Number of posts')\n",
        "fig.savefig(\"Subreddit\", dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Frequency distribution of sentiment\n",
        "df = pd.read_csv('Processeddata.csv', index_col=0)\n",
        "df['periodo'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m')\n",
        "periodo = df[['periodo', 'sentiment']].groupby('periodo').mean()\n",
        "df['pos'] = df['sentiment'] > 0\n",
        "df['neg'] = df['sentiment'] < 0\n",
        "df['neu'] = df['sentiment'] == 0\n",
        "aggr_sent = df[['periodo', 'sentiment']].groupby('periodo').mean()\n",
        "aggr_pol = df[['periodo', 'pos', 'neg', 'neu']].groupby('periodo').sum()\n",
        "aggr_pol['tot'] = aggr_pol.sum(axis=1)\n",
        "aggr_pol = aggr_pol/np.repeat(aggr_pol['tot'].values, 4).reshape(8,4)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "weights = np.ones_like(sentiment_scores) / len(sentiment_scores)\n",
        "perc = np.arange(0, 0.301, 0.05)\n",
        "ax.hist(sentiment_scores, weights=weights, bins=11, edgecolor='white')\n",
        "ax.set_title('Density distribution of \\nsentiment scores')\n",
        "ax.set_yticks(perc)\n",
        "ax.set_yticklabels([str(int(i))+'%' for i in perc*100])\n",
        "ax.set_ylabel('Relative frequency')\n",
        "ax.set_xlabel('Sentiment scores')\n",
        "fig.savefig(\"Sentiment distribution\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Monthly distribution of sentiment\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax.bar(np.arange(8), height=aggr_pol['pos'])\n",
        "ax.bar(np.arange(8), height=aggr_pol['neg'], bottom=aggr_pol['pos'], color='#FF4500')\n",
        "ax.bar(np.arange(8), height=aggr_pol['neu'], bottom=aggr_pol['pos']+aggr_pol['neg'], color='#B2BEB5')\n",
        "colors = ['white', 'black', 'black']\n",
        "polarity = [aggr_pol['pos'], aggr_pol['neg'], aggr_pol['neu']]\n",
        "for i in np.arange(8):\n",
        "  ax.text(i, polarity[0][i]/2,\n",
        "          np.round(polarity[0][i],2), horizontalalignment='center', color='white')\n",
        "for i, p in enumerate(aggr_pol['neg']):\n",
        "  ax.text(i, polarity[1][i]/2 + polarity[0][i],\n",
        "          np.round(polarity[1][i],2), horizontalalignment='center')\n",
        "for i, p in enumerate(aggr_pol['neu']):\n",
        "  ax.text(i, polarity[2][i]/2 + polarity[1][i] + polarity[0][i] - 0.01,\n",
        "          np.round(polarity[2][i], 2), horizontalalignment='center')\n",
        "for i, sentmean in enumerate(periodo['sentiment']):\n",
        "  ax.text(i, 1.11, np.round(sentmean, 2), horizontalalignment='center', fontsize=10)\n",
        "ax.set_title('Percentage sentiment score per month')\n",
        "ax.set_xticks(np.arange(8))\n",
        "ax.set_xticklabels(periodo.index, rotation=45)\n",
        "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.13])\n",
        "ax.set_yticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0,'Mean of \\nsentiment'])\n",
        "ax.set_xlabel('Time')\n",
        "ax.set_ylabel('Sentiment scores (%)')\n",
        "ax.legend(['Positive', 'Negative', 'Neutral'], loc='center right', reverse=True, fontsize=10)\n",
        "ax.plot([-1, 7.5], [1.06, 1.06], color='black')\n",
        "ax.set_xlim([-0.8,9.5])\n",
        "ax.set_ylim([0, 1.2])\n",
        "fig.savefig(\"Monthly sentiment\", dpi=300,  bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Stock prices graphs: nominal and return\n",
        "stock = pd.read_csv('CS.csv')\n",
        "stock['Date'] = pd.to_datetime(stock['Date']).dt.date\n",
        "stock['return'] = stock['Price'].pct_change()\n",
        "stock.dropna(inplace=True)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(stock['Date'], stock['Price'])\n",
        "ax.set_xlim([pd.Timestamp(2022,7,25), pd.Timestamp(2023,3,30)])\n",
        "ax.set_title(\"Credit Suisse's nominal price across time\")\n",
        "ax.set_ylabel('Stock price')\n",
        "ax.set_xlabel('Time', labelpad=10)\n",
        "fig.savefig('Nominal prices', dpi = 300)\n",
        "plt.close()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(stock['Date'], stock['return'])\n",
        "ax.plot([pd.Timestamp(2022,7,25), pd.Timestamp(2023,3,15)], [0, 0], color='#FF4500', linewidth=0.5)\n",
        "ax.set_xlim([pd.Timestamp(2022,7,25), pd.Timestamp(2023,3,30)])\n",
        "ax.set_title('Percentage returns across time')\n",
        "ax.set_xlabel('Time', labelpad=10)\n",
        "ax.set_ylabel('Return')\n",
        "fig.savefig('Returns', dpi = 300)\n",
        "plt.close()\n",
        "\n",
        "# ACF\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10,8))\n",
        "legs = ax[0].acorr(stock['return'])\n",
        "critical = 2/np.sqrt(len(stock['return']))\n",
        "points = ax[0].scatter(legs[0], legs[1])\n",
        "conf_int = ax[0].plot([-1, 11], [critical, critical], color='red')\n",
        "ax[0].plot([-1, 11], [-critical, -critical], color='red')\n",
        "ax[0].set_xlim((-0.5, 10.5))\n",
        "ax[0].set_title('ACF for $u_t$')\n",
        "legs_squared = ax[1].acorr(stock['return']**2)\n",
        "ax[1].scatter(legs_squared[0], legs_squared[1])\n",
        "ax[1].plot([-1, 11], [critical, critical], color='red')\n",
        "ax[1].set_xlim((-0.5, 10.5))\n",
        "ax[1].set_ylim(-0.25, 1.05)\n",
        "ax[1].set_title('ACF for $u_t^2$')\n",
        "ax[1].legend(handles=[points, conf_int[0]], labels=['autocorrelation', 'confindence interval'], loc=(-0.7, -0.2), ncols=2)\n",
        "plt.savefig('Autocorrelation', dpi=300, bbox_inches='tight')\n",
        "plt.close()"
      ],
      "id": "563ee1dd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NLP textual processing"
      ],
      "metadata": {
        "id": "P4ybsY2S6e73"
      },
      "id": "P4ybsY2S6e73"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82093bd7"
      },
      "outputs": [],
      "source": [
        "## NLP Processing: Tokenization, stopwords removal, lemmatization\n",
        "df = pd.read_csv('Processeddata.csv', index_col=0)\n",
        "df.fillna('', inplace=True)\n",
        "\n",
        "# Part Of Speech Tagging\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return 'n'\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Stopwords\n",
        "stop_words_list = stopwords.words(\"english\")\n",
        "more_stopwords = ['credit', 'suisse', 'bank', 'stock', 'click', 'chart', 'market',\n",
        "                  'link', 'tgt', 'price', 'swiss', 'amc', 'ape', 'gme', 'upgrade', 'downgrade',\n",
        "                  'upgraded', 'downgraded', 'outperform', 'underperform', 'perform',\n",
        "                  'overweight', 'equal', 'weight', 'underweight', 'neutral', 'jp', 'morgan',\n",
        "                  'minute', 'topaz', 'meltzer', 'sc', 'basket', 'creditsuisse']\n",
        "less_stopwords = ['not', 'no', 'nor', 'up', 'down', 'out']\n",
        "stop_words_list.extend(more_stopwords)\n",
        "untouchable = ['moass', 'usa']\n",
        "for word in less_stopwords:\n",
        "    stop_words_list.remove(word)\n",
        "stop_words = set(stop_words_list)\n",
        "\n",
        "# Text processing\n",
        "empties = []\n",
        "for i in df.index:\n",
        "    clean = df.loc[i, 'text']\n",
        "    clean = re.sub(r\"[^A-Za-z]\", ' ', clean)\n",
        "    tokens = word_tokenize(clean)\n",
        "    pos = pos_tag(tokens)\n",
        "    filtered_post = []\n",
        "    for word in pos:\n",
        "        if word[0] not in untouchable:\n",
        "            lemm = lemmatizer.lemmatize(word[0], pos=get_wordnet_pos(word[1]))\n",
        "        else:\n",
        "            lemm = word[0]\n",
        "        if lemm not in stop_words:\n",
        "            filtered_post.append(lemm)\n",
        "    clean = ' '.join(filtered_post)\n",
        "    wo_spaces = clean.split()\n",
        "    clean = ' '.join(wo_spaces)\n",
        "    if clean.strip() == '':\n",
        "        empties.append(i)\n",
        "    df.loc[i, 'text'] = clean\n",
        "df.drop(empties, inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.to_csv('Sentdata.csv')"
      ],
      "id": "82093bd7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression figures"
      ],
      "metadata": {
        "id": "Itt-_spZ6iQE"
      },
      "id": "Itt-_spZ6iQE"
    },
    {
      "cell_type": "code",
      "source": [
        "## Regression figures: LASSO geometric intepretation and Regression line\n",
        "\n",
        "# LASSO geometric intepretation\n",
        "lato = 5\n",
        "square = Rectangle((0, -lato*0.5*np.sqrt(2)), lato, lato, edgecolor='#003662', angle=45, alpha=0.5)\n",
        "fig, ax = plt.subplots()\n",
        "ax.add_patch(square)\n",
        "for i in [0.8,1.5,2.5,4]:\n",
        "  ellipse = Ellipse((4, 10.4), width=2*i, height=4*i, angle=145, edgecolor='#FF4500', facecolor='none', linewidth=0.5)\n",
        "  ax.add_patch(ellipse)\n",
        "ax.arrow(0, -5, 0, 22, head_width=0.3, head_length=0.8, fc='black', ec='black', linewidth=0.5)\n",
        "ax.arrow(-5, 0, 18, 0, head_width=0.8, head_length=0.3, fc='black', ec='black', linewidth=0.5)\n",
        "ax.set_xlim(-5, 18)\n",
        "ax.set_ylim(-5, 18)\n",
        "ax.axis('off')\n",
        "ax.scatter(4, 10.4, color='black', s=5)\n",
        "ax.text(4.2, 10.2, r\"$\\hat{\\beta}$\")\n",
        "ax.text(-1.5, 16, r\"$β_2$\")\n",
        "ax.text(12, -1.5, r\"$β_1$\")\n",
        "ax.legend(['Constraint set', 'RSS contour'], reverse=True, loc='center right')\n",
        "ax.set_title('Geometric intepretation of LASSO regularisation', pad=10)\n",
        "fig.savefig('LASSO', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "#Linear regression\n",
        "np.random.seed(3)\n",
        "x = np.linspace(1, 10, 25)\n",
        "y = 0.5*x + 3\n",
        "e = np.random.uniform(-3, 3, 25)\n",
        "y_hat = 0.5*x + 3 + e\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x, y)\n",
        "ax.scatter(x[1:-1], y_hat[1:-1], color='#FF4500')\n",
        "for i in np.arange(1,24):\n",
        "  ax.plot([x[i], x[i]], [y[i], y_hat[i]], color='black', linewidth=0.5)\n",
        "ax.set_xlim(0, 12)\n",
        "ax.set_ylim(0, 12)\n",
        "ax.set_title('Linear Regression with residuals')\n",
        "ax.set_xlabel('x', labelpad=10)\n",
        "ax.set_ylabel('y', rotation=0, labelpad=15)\n",
        "ax.set_xticks(np.linspace(0, 12, 6), labels=np.round(np.linspace(0, 1, 6), 2))\n",
        "ax.set_yticks(np.linspace(2, 12, 5), labels=np.round(np.linspace(0.2, 1, 5), 2))\n",
        "ax.legend(['Regression line', 'Observed values', 'Residuals'], loc=(1, 0.7))\n",
        "fig.savefig('Regression', dpi=300, bbox_inches='tight')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "h_addu-9X2AI"
      },
      "id": "h_addu-9X2AI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2941af13"
      },
      "source": [
        "## 3. Analysis"
      ],
      "id": "2941af13"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation matrix"
      ],
      "metadata": {
        "id": "OmnGdfsC9Fvi"
      },
      "id": "OmnGdfsC9Fvi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation across features\n",
        "daily = pd.read_csv('Dailydata.csv')\n",
        "daily.dropna(inplace=True)\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "corr_matrix = daily.corr(numeric_only=True)\n",
        "im = ax.imshow(corr_matrix, cmap='PuOr', interpolation='nearest')\n",
        "ax.set_yticks(np.arange(corr_matrix.shape[0]), labels=corr_matrix.columns)\n",
        "ax.set_xticks(np.arange(corr_matrix.shape[0]), labels=corr_matrix.columns, rotation=90)\n",
        "ax.figure.colorbar(im)\n",
        "ax.set_title('Correlation across the features', pad=10)\n",
        "fig.savefig('Heatmap', dpi=300, bbox_inches='tight')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "hiXOo_LGLAIT"
      },
      "id": "hiXOo_LGLAIT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WordClouds"
      ],
      "metadata": {
        "id": "tvXHU5Bq85K7"
      },
      "id": "tvXHU5Bq85K7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "703e59d4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "## WordClouds for N-grams\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Sentdata.csv', index_col=0)\n",
        "df.fillna('', inplace=True)\n",
        "\n",
        "# Converting collocations to single units\n",
        "def tuple_keys_to_unique_strings(dictionary):\n",
        "    new_dict = {}\n",
        "    for key_tuple, value in dictionary.items():\n",
        "        new_key = ' '.join(key_tuple)\n",
        "        new_dict[new_key] = value\n",
        "    return new_dict\n",
        "\n",
        "corpus = word_tokenize(' '.join([df.loc[i, 'text'] for i in df.index]))\n",
        "image_path = os.path.join(\"circle.png\")\n",
        "image = Image.open(image_path)\n",
        "imask = np.array(image)\n",
        "colors = [(1.0, 0.270588, 0.2), (0.0, 0.133333, 0.384314)]\n",
        "cmap = LinearSegmentedColormap.from_list('custom', colors, N=2)\n",
        "\n",
        "ngram = ['Single words', 'Bigrams', 'Trigrams', 'Quadgrams']\n",
        "coll_finder = [BigramCollocationFinder, TrigramCollocationFinder, QuadgramCollocationFinder]\n",
        "assoc_measure = [BigramAssocMeasures(), TrigramAssocMeasures(), QuadgramAssocMeasures()]\n",
        "\n",
        "for i in range(4):\n",
        "  if i == 0:\n",
        "    wordcloud = WordCloud(background_color=\"white\", mask=imask, random_state=1, colormap=cmap)\n",
        "    wordcloud.generate(' '.join(corpus))\n",
        "  else:\n",
        "    finder = coll_finder[i-1].from_words(corpus)\n",
        "    fdist = finder.score_ngrams(assoc_measure[i-1].raw_freq)\n",
        "    wordcloud = WordCloud(background_color=\"white\", mask=imask, random_state=1, colormap=cmap)\n",
        "    wordcloud.generate_from_frequencies(tuple_keys_to_unique_strings(dict(fdist)))\n",
        "  fig, ax = plt.subplots(figsize = (8,5))\n",
        "  ax.set_title(f'{ngram[i]} Frequency', fontsize=15)\n",
        "  ax.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "  ax.set_ylim([1350, 50])\n",
        "  ax.set_xlim([50, 1350])\n",
        "  ax.axis('off')\n",
        "  fig.savefig(ngram[i], dpi=300)\n",
        "  plt.close()"
      ],
      "id": "703e59d4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OLS: Returns vs posts data & posts vs financial data"
      ],
      "metadata": {
        "id": "CPR23PQQ9J7N"
      },
      "id": "CPR23PQQ9J7N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16ca4901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e286cf-cb0f-43e8-bfbf-f09f3b6a1b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                returns   R-squared:                       0.052\n",
            "Model:                            OLS   Adj. R-squared:                  0.015\n",
            "Method:                 Least Squares   F-statistic:                     1.399\n",
            "Date:                Mon, 20 Nov 2023   Prob (F-statistic):              0.229\n",
            "Time:                        22:09:39   Log-Likelihood:                 228.51\n",
            "No. Observations:                 134   AIC:                            -445.0\n",
            "Df Residuals:                     128   BIC:                            -427.6\n",
            "Df Model:                           5                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.0071      0.004     -1.828      0.070      -0.015       0.001\n",
            "sentiment      0.0045      0.004      1.142      0.256      -0.003       0.012\n",
            "length         0.0035      0.005      0.684      0.495      -0.007       0.013\n",
            "posts         -0.0081      0.004     -2.047      0.043      -0.016      -0.000\n",
            "karma         -0.0041      0.005     -0.803      0.423      -0.014       0.006\n",
            "upvote         0.0009      0.004      0.218      0.828      -0.007       0.009\n",
            "==============================================================================\n",
            "Omnibus:                       14.421   Durbin-Watson:                   2.130\n",
            "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               47.901\n",
            "Skew:                          -0.101   Prob(JB):                     3.97e-11\n",
            "Kurtosis:                       5.922   Cond. No.                         2.19\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  posts   R-squared:                       0.765\n",
            "Model:                            OLS   Adj. R-squared:                  0.756\n",
            "Method:                 Least Squares   F-statistic:                     83.38\n",
            "Date:                Mon, 20 Nov 2023   Prob (F-statistic):           1.46e-38\n",
            "Time:                        22:09:39   Log-Likelihood:                -475.84\n",
            "No. Observations:                 134   AIC:                             963.7\n",
            "Df Residuals:                     128   BIC:                             981.1\n",
            "Df Model:                           5                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          8.0149      0.745     10.753      0.000       6.540       9.490\n",
            "price          2.4227      1.144      2.117      0.036       0.158       4.687\n",
            "volume         9.6668      1.485      6.511      0.000       6.729      12.605\n",
            "volatility     3.3077      0.900      3.677      0.000       1.528       5.088\n",
            "cds            6.1128      1.673      3.655      0.000       2.803       9.422\n",
            "returns        0.6119      0.810      0.756      0.451      -0.990       2.214\n",
            "==============================================================================\n",
            "Omnibus:                      140.576   Durbin-Watson:                   1.477\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3089.424\n",
            "Skew:                           3.679   Prob(JB):                         0.00\n",
            "Kurtosis:                      25.342   Cond. No.                         4.55\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# Regression returns vs posts data\n",
        "daily = pd.read_csv('Dailydata.csv')\n",
        "daily.dropna(inplace=True)\n",
        "X = StandScal(daily[['sentiment', 'length', 'posts', 'karma', 'upvote']].copy())\n",
        "X = sm.add_constant(X)\n",
        "Y = daily['returns']\n",
        "reg = sm.OLS(Y, X)\n",
        "model = reg.fit()\n",
        "print(model.summary())\n",
        "\n",
        "# Regression posts vs financial data\n",
        "X = StandScal(daily[['price', 'volume', 'volatility', 'cds', 'returns']].copy())\n",
        "X = sm.add_constant(X)\n",
        "Y = daily['posts']\n",
        "reg = sm.OLS(Y, X)\n",
        "model = reg.fit()\n",
        "print(model.summary())"
      ],
      "id": "16ca4901"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN & Word2Vec: Returns vs post data"
      ],
      "metadata": {
        "id": "lEmDzomq9R06"
      },
      "id": "lEmDzomq9R06"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79c43994-d76a-4007-b478-3c89809025a3",
        "outputId": "963ec527-9074-4c69-dc85-d63d2d6e7bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K optimal: 39 \n",
            "Score: 0.6666666666666666\n",
            "K optimal: 9 \n",
            "Score: 0.6\n",
            "K optimal: 9 \n",
            "Score: 0.6\n"
          ]
        }
      ],
      "source": [
        "# Posts data\n",
        "df = pd.read_csv('Sentdata.csv', index_col=0)\n",
        "daily = pd.read_csv('Dailydata.csv')\n",
        "daily.dropna(inplace=True)\n",
        "\n",
        "dataset = StandScal(daily)\n",
        "dataset['returns'] = dataset['returns']>=0\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "train = dataset[dataset['date']<pd.to_datetime('2023-01-01')]\n",
        "test = dataset[dataset['date']>=pd.to_datetime('2023-01-01')]\n",
        "X_train = train[['posts', 'karma', 'upvote', 'length', 'sentiment']].values\n",
        "Y_train = train['returns'].values\n",
        "X_test = test[['posts', 'karma', 'upvote', 'length', 'sentiment']].values\n",
        "Y_test = test['returns'].values\n",
        "\n",
        "scores = []\n",
        "for k in np.arange(3, 52, 2):\n",
        "    knn = KNeighborsClassifier(n_neighbors = k)\n",
        "    knn.fit(X_train, Y_train)\n",
        "    scores.append(knn.score(X_test, Y_test))\n",
        "print('K optimal:', np.arange(3, 52, 2)[np.argmax(scores)], '\\nScore:', np.max(scores))\n",
        "\n",
        "#  Word2vec embedding\n",
        "corpus = [word_tokenize(df.loc[i, 'text']) for i in df.index]\n",
        "w2v = Word2Vec(corpus, min_count=1, vector_size=300)\n",
        "\n",
        "post_w2v_df = []\n",
        "for i in df.index:\n",
        "  post_score = 0\n",
        "  for word in df.loc[i, 'text'].split():\n",
        "    post_score+=w2v.wv[word]\n",
        "  post_w2v_df.append(post_score)\n",
        "post_w2v_df = pd.DataFrame(post_w2v_df, index=pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d'))\n",
        "post_w2v_df.columns=[str(j) for j in post_w2v_df.columns]\n",
        "\n",
        "# W2v\n",
        "post_w2v_df.sort_index(inplace=True)\n",
        "ts_word = post_w2v_df.groupby(post_w2v_df.index).mean()\n",
        "ts_word = ts_word.loc[daily['date'].astype('str')]\n",
        "ts_word['returns'] = dataset['returns'].values\n",
        "ts_word['date'] = pd.to_datetime(ts_word.index)\n",
        "train = ts_word[ts_word['date']<pd.to_datetime('2023-01-01')]\n",
        "test = ts_word[ts_word['date']>=pd.to_datetime('2023-01-01')]\n",
        "X_train = train.drop(['returns', 'date'], axis=1)\n",
        "X_test = test.drop(['returns', 'date'], axis=1)\n",
        "Y_train = train['returns'].values\n",
        "Y_test = test['returns'].values\n",
        "\n",
        "scores = []\n",
        "for k in np.arange(3, 51, 2):\n",
        "    knn = KNeighborsClassifier(n_neighbors = k)\n",
        "    knn.fit(X_train, Y_train)\n",
        "    scores.append(knn.score(X_test, Y_test))\n",
        "print('K optimal:', np.arange(3, 51, 2)[np.argmax(scores)], '\\nScore:', np.max(scores))\n",
        "\n",
        "# Posts + w2v\n",
        "ts_word.drop(['date', 'returns'], axis=1, inplace=True)\n",
        "for c in dataset.columns:\n",
        "  ts_word[c] = dataset[c].values\n",
        "train = ts_word[ts_word['date']<pd.to_datetime('2023-01-01')]\n",
        "test = ts_word[ts_word['date']>=pd.to_datetime('2023-01-01')]\n",
        "X_train = train.drop(['returns', 'date', 'price', 'volume', 'volatility', 'cds', 'returns'], axis=1)\n",
        "X_test = test.drop(['returns', 'date', 'price', 'volume', 'volatility', 'cds', 'returns'], axis=1)\n",
        "Y_train = train['returns'].values\n",
        "Y_test = test['returns'].values\n",
        "\n",
        "scores = []\n",
        "for k in np.arange(3, 51, 2):\n",
        "    knn = KNeighborsClassifier(n_neighbors = k)\n",
        "    knn.fit(X_train, Y_train)\n",
        "    scores.append(knn.score(X_test, Y_test))\n",
        "print('K optimal:', np.arange(3, 51, 2)[np.argmax(scores)], '\\nScore:', np.max(scores))"
      ],
      "id": "79c43994-d76a-4007-b478-3c89809025a3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Posts data\n",
        "df = pd.read_csv('Sentdata.csv', index_col=0)\n",
        "daily = pd.read_csv('Dailydata.csv')\n",
        "daily.dropna(inplace=True)\n",
        "dataset = StandScal(daily)\n",
        "dataset['returns'] = dataset['returns']>=0\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "train = dataset[dataset['date']<pd.to_datetime('2023-01-01')]\n",
        "test = dataset[dataset['date']>=pd.to_datetime('2023-01-01')]\n",
        "X = dataset[['sentiment', 'posts']]\n",
        "Y = dataset['returns'].values\n",
        "X_train = train[['sentiment', 'posts']]\n",
        "Y_train = train['returns'].values\n",
        "X_test = test[['sentiment', 'posts']]\n",
        "Y_test = test['returns'].values\n",
        "knn = KNeighborsClassifier(n_neighbors = 9)\n",
        "knn.fit(X_train, Y_train)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "disp = DecisionBoundaryDisplay.from_estimator(knn, X_test, response_method=\"predict\",\n",
        "                                              plot_method=\"pcolormesh\", shading=\"auto\", alpha=0.65, ax=ax)\n",
        "scatter = disp.ax_.scatter(X.iloc[:, 0], X.iloc[:, 1], c=Y, edgecolors=\"k\", s=50)\n",
        "disp.ax_.legend(scatter.legend_elements()[0], ['Price Down', 'Price Up'], loc=\"upper left\", title=\"Classes\")\n",
        "ax.set_ylim((-1, 3))\n",
        "ax.set_title('KNN decision boundaries')\n",
        "plt.savefig('KNN boundaries', dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "LWnCr97y_REB"
      },
      "id": "LWnCr97y_REB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post traffic analysis"
      ],
      "metadata": {
        "id": "YMEczA1m9m8_"
      },
      "id": "YMEczA1m9m8_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94ea2e82-b9b6-4754-bb5c-d049526a03a3"
      },
      "outputs": [],
      "source": [
        "# Post traffic analysis\n",
        "peaks = ['2022-10-03', '2022-10-27', '2022-11-23', '2023-03-15']\n",
        "i_coord = [63, 87, 114, 226]\n",
        "y_coord = [83, 47, 21, 135]\n",
        "daily = pd.read_csv('Dailydata.csv')\n",
        "daily['date'] = pd.to_datetime(daily['date']).dt.date\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax.plot(daily.index, daily['posts'])\n",
        "ax.scatter(i_coord, y_coord, c='red', s=70)\n",
        "for i,y in zip(i_coord, y_coord):\n",
        "    sentiment = np.round(daily.loc[i, 'sentiment'],2)\n",
        "    date = daily.loc[i, 'date']\n",
        "    ax.text(i,y+3, date, fontsize=10)\n",
        "ax.set_ylim(-1, 150)\n",
        "ax.set_title('Peaks of online activity', fontsize=15)\n",
        "ax.set_ylabel('Number of posts')\n",
        "ax.set_xticks([i for i in np.arange(226) if daily.loc[i, 'date'].day == 1],\n",
        "              labels=[pd.Timestamp(daily.loc[i, 'date']).month_name() for i in np.arange(226) if daily.loc[i, 'date'].day == 1])\n",
        "fig.savefig(\"Peaks of activity\", dpi=300)\n",
        "plt.close()"
      ],
      "id": "94ea2e82-b9b6-4754-bb5c-d049526a03a3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-peak and post-peak activity"
      ],
      "metadata": {
        "id": "bnOXgJqJ_ePE"
      },
      "id": "bnOXgJqJ_ePE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96a26099-771b-4a4d-9740-3357bdead565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "c73171c1-de27-40a4-e03b-305022ee43f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           Average sentiment  Average return  Std sentiment  std returns  \\\n",
              "Pre-peak            0.171874       -0.005220       0.412206     0.028259   \n",
              "Post-peak          -0.001396       -0.020031       0.172191     0.076010   \n",
              "\n",
              "           Correlation sentiment-returns  \n",
              "Pre-peak                            0.29  \n",
              "Post-peak                           0.07  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb7039fe-9756-4505-916c-f1648bb3df96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Average sentiment</th>\n",
              "      <th>Average return</th>\n",
              "      <th>Std sentiment</th>\n",
              "      <th>std returns</th>\n",
              "      <th>Correlation sentiment-returns</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pre-peak</th>\n",
              "      <td>0.171874</td>\n",
              "      <td>-0.005220</td>\n",
              "      <td>0.412206</td>\n",
              "      <td>0.028259</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Post-peak</th>\n",
              "      <td>-0.001396</td>\n",
              "      <td>-0.020031</td>\n",
              "      <td>0.172191</td>\n",
              "      <td>0.076010</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb7039fe-9756-4505-916c-f1648bb3df96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb7039fe-9756-4505-916c-f1648bb3df96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb7039fe-9756-4505-916c-f1648bb3df96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cfc9c0d9-e409-4ff3-9bfd-b900bffa66ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfc9c0d9-e409-4ff3-9bfd-b900bffa66ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cfc9c0d9-e409-4ff3-9bfd-b900bffa66ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Pre and post peak analysis\n",
        "\n",
        "daily = pd.read_csv('Dailydata.csv')\n",
        "daily.dropna(inplace=True)\n",
        "daily['date'] = pd.to_datetime(daily['date']).dt.date\n",
        "daily.sort_values('date', inplace=True)\n",
        "peaks = pd.to_datetime(['2022-10-03', '2022-10-27', '2022-11-23', '2023-03-09']).date\n",
        "window = 5\n",
        "\n",
        "df_prepost = []\n",
        "for i in range(2):\n",
        "  df_window = []\n",
        "  for p in peaks:\n",
        "    if i == 0:\n",
        "      df_window.append(daily[daily['date']<p].tail(window))\n",
        "    else:\n",
        "      df_window.append(daily[daily['date']>=p].head(window))\n",
        "  df_window = pd.concat(df_window, ignore_index=True)\n",
        "  coef_window = np.round(np.corrcoef(df_window['sentiment'], df_window['returns'])[0,1], 2)\n",
        "  desc_window = [df_window['sentiment'].mean(), df_window['returns'].mean(),\n",
        "                 df_window['sentiment'].std(), df_window['returns'].std(),\n",
        "                 coef_window]\n",
        "  df_prepost.append(desc_window)\n",
        "\n",
        "  X = StandScal(df_window[['sentiment', 'posts', 'karma', 'upvote']].copy())\n",
        "  X = sm.add_constant(X)\n",
        "  Y = df_window['returns']\n",
        "  reg = sm.OLS(Y, X)\n",
        "  model = reg.fit()\n",
        "  #print(model.summary())\n",
        "\n",
        "desc_df = pd.DataFrame([df_prepost[0], df_prepost[1]], index = ['Pre-peak', 'Post-peak'],\n",
        "              columns=['Average sentiment', 'Average return', 'Std sentiment', 'std returns', 'Correlation sentiment-returns'])\n",
        "display(desc_df)"
      ],
      "id": "96a26099-771b-4a4d-9740-3357bdead565"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Short selling"
      ],
      "metadata": {
        "id": "2EYvWsuQDYhe"
      },
      "id": "2EYvWsuQDYhe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cd69cda-663d-4b89-9810-12c7c817df4f"
      },
      "outputs": [],
      "source": [
        "## Short selling\n",
        "bim = pd.read_csv('Shortdata.csv')\n",
        "bim = StandScal(bim)\n",
        "X = StandScal(bim[['karma', 'upvote', 'length', 'sentiment', 'posts', 'price']].copy())\n",
        "X = sm.add_constant(X)\n",
        "Y = bim['shares']\n",
        "reg = sm.OLS(Y, X)\n",
        "model = reg.fit()\n",
        "#print(model.summary())"
      ],
      "id": "8cd69cda-663d-4b89-9810-12c7c817df4f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding + Lasso"
      ],
      "metadata": {
        "id": "FAtkP3FLDe6H"
      },
      "id": "FAtkP3FLDe6H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9777467d"
      },
      "outputs": [],
      "source": [
        "## Embedding representation + Lasso Regression for Variable Selection\n",
        "\n",
        "# Colors for wordclouds\n",
        "def get_color(value):\n",
        "    return '#003662' if value >= 0 else '#FF4500'\n",
        "\n",
        "# Load the dataset\n",
        "daily = pd.read_csv('Dailydata.csv')\n",
        "daily.dropna(inplace=True)\n",
        "daily = StandScal(daily)\n",
        "\n",
        "# Daily Aggregation + WordCloud\n",
        "def LASSOed(wordembed, figname, min_lambda, max_lambda):\n",
        "  wordembed.sort_index(inplace=True)\n",
        "  ts_word = wordembed.groupby(wordembed.index).sum()\n",
        "  ts_word = ts_word.loc[daily['date'].astype('str')]\n",
        "  ts_word['CS_returns'] = daily['returns'].values\n",
        "  ts_word['CS_date'] = pd.to_datetime(ts_word.index)\n",
        "  train = ts_word[ts_word['CS_date']<pd.to_datetime('2023-01-01')]\n",
        "  test = ts_word[ts_word['CS_date']>=pd.to_datetime('2023-01-01')]\n",
        "  X_train = train.drop(['CS_returns', 'CS_date'], axis=1)\n",
        "  X_test = test.drop(['CS_returns', 'CS_date'], axis=1)\n",
        "  Y_train = train['CS_returns'].values\n",
        "  Y_test = test['CS_returns'].values\n",
        "  scores = []\n",
        "  lambda_array = np.linspace(min_lambda, max_lambda, 25)\n",
        "  for l in lambda_array:\n",
        "      reg = Lasso(alpha=l, max_iter=100000)\n",
        "      reg.fit(X_train, Y_train)\n",
        "      scores.append(reg.score(X_test, Y_test))\n",
        "  best_l = lambda_array[np.argmax(scores)]\n",
        "  print('Lasso optimal:', best_l, '\\nScore:', np.max(scores))\n",
        "  reg = Lasso(alpha=best_l, max_iter=100000)\n",
        "  reg.fit(X_train, Y_train)\n",
        "  survivors = pd.DataFrame(reg.coef_, wordembed.columns, columns=['coef'])\n",
        "  coeffic = survivors[survivors['coef']!=0]['coef']\n",
        "  word_colors = {word: get_color(value) for word, value in zip(coeffic.index, coeffic)}\n",
        "  fig, ax = plt.subplots(figsize = (8,5))\n",
        "  wordcloud = WordCloud(background_color=\"white\", mask=imask, random_state=1,\n",
        "                        color_func=lambda word, *args, **kwargs: word_colors[word])\n",
        "  wordcloud.generate_from_frequencies(dict(coeffic**2))\n",
        "  ax.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "  ax.set_title(f'{figname}: LASSO coefficients', fontsize=15)\n",
        "  ax.axis('off')\n",
        "  legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#003662', label='Positive Coefficient'),\n",
        "                    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF4500', label='Negative Coefficient')]\n",
        "  ax.legend(handles=legend_elements, loc =(0.8,0.85), fontsize='x-small')\n",
        "  fig.savefig(figname, dpi=300, bbox_inches='tight')\n",
        "  plt.close()"
      ],
      "id": "9777467d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d40fe791",
        "outputId": "686f11b0-8874-4e41-9994-621b849d589f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso optimal: 0.15 \n",
            "Score: -1.4538223124226524\n",
            "Lasso optimal: 0.01 \n",
            "Score: -0.8063408660959512\n"
          ]
        }
      ],
      "source": [
        "## Bag-of-word\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Sentdata.csv', index_col=0)\n",
        "\n",
        "vec_name = ['Bag-of-word', 'tf-idf']\n",
        "vectorizers = [CountVectorizer(), TfidfVectorizer()]\n",
        "corpus = [df.loc[i, 'text'] for i in df.index]\n",
        "min_lambda_array = [0.05, 0.001]\n",
        "max_lambda_array = [0.15, 0.01]\n",
        "penalties = [50, 5]\n",
        "for v in range(2):\n",
        "  vectorizer = vectorizers[v]\n",
        "  encoded = vectorizer.fit_transform(corpus)\n",
        "  features = vectorizer.get_feature_names_out()\n",
        "  onehot = pd.DataFrame(encoded.toarray(), columns=features,\n",
        "                            index=pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d'))\n",
        "  onehot.drop(onehot.columns[onehot.sum()<penalties[v]], axis=1, inplace=True)\n",
        "  LASSOed(onehot, vec_name[v], min_lambda_array[v], max_lambda_array[v])"
      ],
      "id": "d40fe791"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GARCH"
      ],
      "metadata": {
        "id": "9aO8rORykc1E"
      },
      "id": "9aO8rORykc1E"
    },
    {
      "cell_type": "code",
      "source": [
        "stock = pd.read_csv('CS.csv')\n",
        "stock['Date'] = pd.to_datetime(stock['Date']).dt.date\n",
        "stock['returns'] = stock['Price'].pct_change()*100\n",
        "stock['returns'] = stock['returns']\n",
        "stock.dropna(inplace=True)\n",
        "\n",
        "np.random.seed(0)\n",
        "model = arch.arch_model(stock['returns'], vol='Arch', p=3)\n",
        "results = model.fit(update_freq=0, disp='off')\n",
        "print(results.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6l18HYMkcHR",
        "outputId": "701b3ffd-3235-4ae6-b18b-fe91c5c4542f"
      },
      "id": "Z6l18HYMkcHR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Constant Mean - ARCH Model Results                      \n",
            "==============================================================================\n",
            "Dep. Variable:                returns   R-squared:                       0.000\n",
            "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
            "Vol Model:                       ARCH   Log-Likelihood:               -453.930\n",
            "Distribution:                  Normal   AIC:                           917.860\n",
            "Method:            Maximum Likelihood   BIC:                           933.173\n",
            "                                        No. Observations:                  158\n",
            "Date:                Mon, Nov 20 2023   Df Residuals:                      157\n",
            "Time:                        22:09:53   Df Model:                            1\n",
            "                                Mean Model                                \n",
            "==========================================================================\n",
            "                 coef    std err          t      P>|t|    95.0% Conf. Int.\n",
            "--------------------------------------------------------------------------\n",
            "mu            -0.5866      0.337     -1.743  8.136e-02 [ -1.246,7.308e-02]\n",
            "                               Volatility Model                              \n",
            "=============================================================================\n",
            "                 coef    std err          t      P>|t|       95.0% Conf. Int.\n",
            "-----------------------------------------------------------------------------\n",
            "omega         18.0972      4.394      4.118  3.818e-05      [  9.484, 26.710]\n",
            "alpha[1]       0.0000  4.438e-02      0.000      1.000 [-8.699e-02,8.699e-02]\n",
            "alpha[2]       0.0000  2.260e-02      0.000      1.000 [-4.430e-02,4.430e-02]\n",
            "alpha[3]       0.0135      0.101      0.134      0.894      [ -0.184,  0.211]\n",
            "=============================================================================\n",
            "\n",
            "Covariance estimator: robust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backward selection"
      ],
      "metadata": {
        "id": "tRdbIA6R1drz"
      },
      "id": "tRdbIA6R1drz"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Dailydata.csv', index_col=0)\n",
        "df.dropna(inplace=True)\n",
        "X = StandScal(df[['sentiment', 'upvote', 'posts', 'length', 'karma']].copy())\n",
        "Y = df['returns']\n",
        "reg = LinearRegression()\n",
        "n = X.shape[0]\n",
        "\n",
        "reg.fit(X, Y)\n",
        "p = reg.n_features_in_\n",
        "print(reg.feature_names_in_, 1-((1-reg.score(X, Y))*((n-1)/(n-p-2))))\n",
        "\n",
        "reg = LinearRegression()\n",
        "for i in range(4):\n",
        "  sfs = RFE(reg, n_features_to_select=4-i)\n",
        "  sfs.fit(X, Y)\n",
        "  p = sfs.n_features_\n",
        "  print(sfs.get_feature_names_out(), 1-((1-sfs.score(X, Y))*((n-1)/(n-p-2))))\n"
      ],
      "metadata": {
        "id": "clpDbkKL-emD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5de90af-933d-4f78-f2f3-dbc46fc7a030"
      },
      "id": "clpDbkKL-emD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sentiment' 'upvote' 'posts' 'length' 'karma'] 0.007022778225361459\n",
            "['sentiment' 'posts' 'length' 'karma'] 0.014413661074284989\n",
            "['sentiment' 'posts' 'karma'] 0.01877223273493589\n",
            "['sentiment' 'posts'] 0.024637781137960224\n",
            "['posts'] 0.02084657906736853\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}